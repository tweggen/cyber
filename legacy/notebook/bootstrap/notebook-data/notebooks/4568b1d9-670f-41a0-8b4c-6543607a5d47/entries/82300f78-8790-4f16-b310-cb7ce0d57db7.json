{
  "id": "82300f78-8790-4f16-b310-cb7ce0d57db7",
  "content": "DECISION 2-1: Coherence Model Implementation\n\nAUTHOR: agent-coherence\n\nDESIGN DECISIONS:\n\n1. MODULE STRUCTURE:\n   - tfidf.rs: TF-IDF computation with tokenization, stop word removal, and cosine similarity\n   - clustering.rs: Agglomerative clustering with configurable similarity threshold\n   - coherence.rs: CoherenceSnapshot type and cluster assignment logic\n   - All modules exported from notebook-entropy/src/lib.rs\n\n2. TOKENIZATION APPROACH:\n   - Split on whitespace using Unicode segmentation\n   - Lowercase all tokens\n   - Remove punctuation (keep alphanumeric and hyphens)\n   - Built-in English stop word list (approximately 100 common words)\n   - Minimum token length of 2 characters\n\n3. TF-IDF IMPLEMENTATION:\n   - Term Frequency: Raw count divided by total tokens in document\n   - Inverse Document Frequency: log(N/df) where N is total documents, df is document frequency\n   - Document vector: sparse representation as HashMap<String, f64>\n   - Cosine similarity for comparing document vectors\n\n4. CLUSTERING DESIGN:\n   - Cluster struct: { id: ClusterId, topic_keywords: Vec<String>, entry_ids: Vec<EntryId>, reference_density: f64 }\n   - ClusterId is a simple u64 wrapper for type safety\n   - Agglomerative clustering: start with each entry as singleton, merge most similar pairs\n   - Merge threshold: configurable, default 0.3 cosine similarity\n   - Top-5 keywords per cluster by TF-IDF weight sum across cluster entries\n\n5. COHERENCE SNAPSHOT:\n   - CoherenceSnapshot { clusters: Vec<Cluster>, corpus_stats: CorpusStats, timestamp: CausalPosition }\n   - CorpusStats holds document frequencies for IDF computation\n   - Methods: assign_to_cluster(entry) -> Option<ClusterId> using max similarity above threshold\n   - Serialization via serde for persistence (JSONB storage)\n\n6. REFERENCE DENSITY:\n   - Formula: within_cluster_edges / possible_edges\n   - possible_edges = n * (n-1) / 2 for n entries (undirected graph)\n   - within_cluster_edges = count of references where both entries in same cluster\n   - Returns 1.0 for singleton clusters (by convention)\n\n7. INCREMENTAL UPDATE:\n   - Adding entry: find best cluster or create new singleton\n   - Update corpus stats (document frequencies)\n   - Recalculate cluster keywords if entry added\n   - Update reference density for affected clusters\n\n8. DEPENDENCIES:\n   - unicode-segmentation = \"1.11\" for proper word segmentation\n   - serde (workspace) for serialization\n   - notebook-core (workspace) for EntryId, CausalPosition types\n\n9. TEST COVERAGE:\n   - Tokenization edge cases (empty, punctuation-only, unicode)\n   - TF-IDF computation correctness\n   - Cosine similarity properties (self-similarity = 1, commutative)\n   - Clustering behavior (singleton, merge, threshold)\n   - Reference density calculation\n   - Serialization round-trips\n\nREFERENCES: task-assignment 2-1, entropy model entry, core types from task-result 0-2",
  "content_type": "text/plain",
  "topic": "decision 2-1",
  "references": [
    "381d238b-a526-4829-b57f-5097635af47b",
    "509be5e4-b5e7-4f16-845e-b17e63b44605",
    "46ee8ade-fba4-4238-a0fd-27a1a838d8fa"
  ],
  "revision_of": null,
  "author": "agent-coherence",
  "causal_position": {
    "sequence": 52,
    "activity_context": {
      "entries_since_last_by_author": 0,
      "total_notebook_entries": 51,
      "recent_entropy": 21.1
    }
  },
  "created": "2026-02-05T10:58:07.616257+00:00",
  "integration_cost": {
    "entries_revised": 0,
    "references_broken": 0,
    "catalog_shift": 0.0,
    "orphan": false
  }
}